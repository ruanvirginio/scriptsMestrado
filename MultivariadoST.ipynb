{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruanvirginio/scriptsMestrado/blob/main/MultivariadoST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWZQ3DHjBt6y"
      },
      "source": [
        "#### Importando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uHDpMOPIclGg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "url_base = \"https://media.githubusercontent.com/media/ruanvirginio/scriptsMestrado/refs/heads/main/Medicoes_2018-2024.csv\"\n",
        "df = pd.read_csv(url_base,  sep=',', encoding='latin-1', skiprows=1)\n",
        "\n",
        "url_GD = \"https://media.githubusercontent.com/media/ruanvirginio/scriptsMestrado/refs/heads/main/EntrantesGD.csv\"\n",
        "gd = pd.read_csv(url_GD,  sep=';', encoding='latin-1')\n",
        "\n",
        "url_clientes = \"https://media.githubusercontent.com/media/ruanvirginio/scriptsMestrado/refs/heads/main/Base_Quantidade_Clientes.csv\"\n",
        "clientes = pd.read_csv(url_clientes, sep=';', encoding='latin-1')\n",
        "\n",
        "df['Potência Ativa'] = pd.to_numeric(df['Potência Ativa'].str.replace(',', '.'), errors='coerce')\n",
        "df['Potência Reativa'] = pd.to_numeric(df['Potência Reativa'].str.replace(',', '.'), errors='coerce')\n",
        "\n",
        "gd.rename(columns={\n",
        "    'Tempo': 'datahora',\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEP7Eb0QBxlL"
      },
      "source": [
        "#### Funções para tratar Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqFeLkU9Ad06"
      },
      "outputs": [],
      "source": [
        "# Função para aplicar o filtro IQR\n",
        "def filtrar_coluna_iqr(df, coluna):\n",
        "    Q1 = df[coluna].quantile(0.25)\n",
        "    Q3 = df[coluna].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 2 * IQR\n",
        "    upper_bound = Q3 + 3.2 * IQR\n",
        "\n",
        "    return df[(df[coluna] >= lower_bound) & (df[coluna] <= upper_bound)]\n",
        "\n",
        "# Função para aplicar o filtro baseado em Média Móvel\n",
        "def filtrar_coluna_media_movel(df, coluna, janela=20, threshold=4):\n",
        "\n",
        "    media_movel = df[coluna].rolling(window=janela, center=True).mean()\n",
        "    desvio = np.abs(df[coluna] - media_movel)\n",
        "\n",
        "    limite_superior = media_movel + threshold * desvio.std()\n",
        "    limite_inferior = media_movel - threshold * desvio.std()\n",
        "\n",
        "    return df[(df[coluna] >= limite_inferior) & (df[coluna] <= limite_superior)]\n",
        "\n",
        "# Função para aplicar o filtro baseado em Z-Score\n",
        "def filtrar_coluna_zscore(df, coluna, threshold=3):\n",
        "    media = df[coluna].mean()\n",
        "    desvio_padrao = df[coluna].std()\n",
        "    z_scores = (df[coluna] - media) / desvio_padrao\n",
        "\n",
        "    return df[np.abs(z_scores) < threshold]\n",
        "\n",
        "# Função que aplica o filtro escolhido\n",
        "def aplicar_filtro(df, coluna, metodo='iqr', janela=20, threshold=4, z_threshold=3):\n",
        "    if metodo == 'iqr':\n",
        "        return filtrar_coluna_iqr(df, coluna)\n",
        "    elif metodo == 'media_movel':\n",
        "        return filtrar_coluna_media_movel(df, coluna, janela=janela, threshold=threshold)\n",
        "    elif metodo == 'zscore':\n",
        "        return filtrar_coluna_zscore(df, coluna, threshold=z_threshold)\n",
        "    else:\n",
        "        raise ValueError(\"Método inválido! Escolha entre 'iqr', 'media_movel' ou 'zscore'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akBfx8K3B3YZ"
      },
      "source": [
        "#### Tratamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uuy-qBpfeMh"
      },
      "outputs": [],
      "source": [
        "## Tratando \"CLIENTES\"\n",
        "\n",
        "clientes['DATA'] = pd.to_datetime(clientes['DATA'])\n",
        "\n",
        "# One-hot encoding nas colunas de interesse\n",
        "dummies = pd.get_dummies(clientes[['CLASSE', 'DSC_GRUPO_FORNECIMENTO']].astype(str),\n",
        "                         prefix=['classe', 'fornec'])\n",
        "\n",
        "# Multiplicando cada coluna pelo valor de QTD_CLIENTES\n",
        "dummies_mult = dummies.multiply(clientes['QTD_CLIENTES'], axis=0)\n",
        "\n",
        "# Concatenando com as colunas TRAFO e DATA\n",
        "df_transf = pd.concat([clientes[['TRAFO', 'DATA']], dummies_mult], axis=1)\n",
        "\n",
        "# Se por acaso houver mais de uma linha para uma mesma combinação de TRAFO e DATA, somamos\n",
        "df_final = df_transf.groupby(['TRAFO', 'DATA']).sum().reset_index()\n",
        "\n",
        "# Essa clase não existe\n",
        "df_final.drop('classe_0', axis=1)\n",
        "\n",
        "df_final.rename(columns={\n",
        "    'DATA': 'datahora',\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwlqWpwyfeMh"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={\n",
        "    'Potência Ativa': 'P',\n",
        "    'Potência Reativa': 'Q',\n",
        "    'Data/Hora Medição': 'datahora',\n",
        "    'Equipamento Medição': 'TRAFO'\n",
        "}, inplace=True)\n",
        "\n",
        "df['datahora'] = pd.to_datetime(df['datahora'], format='%d/%m/%Y %H:%M:%S')\n",
        "gd['datahora'] = pd.to_datetime(gd['datahora'], format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "df = pd.merge(df, gd, on=['datahora', 'TRAFO'])\n",
        "\n",
        "df = pd.merge(df, df_final, on=['datahora', 'TRAFO'])\n",
        "\n",
        "df['P'] = df['P'].abs()  # salvando o módulo dos valores\n",
        "df['Q'] = df['Q'].abs()\n",
        "df['S'] = np.sqrt(df['P']**2 + df['Q']**2)  # Calculando a potência aparente (S), em kVA\n",
        "\n",
        "# Removendo linhas com S = 0\n",
        "df = df[df['S'] != 0]\n",
        "\n",
        "# DataFrame final para armazenar os dados filtrados\n",
        "df_filtrado = pd.DataFrame()\n",
        "\n",
        "# Escolha do método de filtragem ('iqr', 'media_movel' ou 'zscore')\n",
        "metodo_filtro = 'iqr'\n",
        "\n",
        "# Aplicando o filtro pra limpar os outliers pra cada transformador\n",
        "for trafo in df['TRAFO'].unique():\n",
        "    df_trafo = df[df['TRAFO'] == trafo]\n",
        "\n",
        "    df_trafo_filtrado = aplicar_filtro(df_trafo, 'S', metodo=metodo_filtro, janela=20, threshold=4, z_threshold=3)\n",
        "\n",
        "    # Adicionar os dados filtrados ao DataFrame final\n",
        "    df_filtrado = pd.concat([df_filtrado, df_trafo_filtrado], ignore_index=True)\n",
        "\n",
        "# Ordenando e removendo duplicatas\n",
        "df_filtrado = df_filtrado.sort_values(by=['TRAFO', 'datahora'])\n",
        "df_filtrado = df_filtrado.drop_duplicates(subset=['datahora', 'TRAFO'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ebk8QYufeMi"
      },
      "outputs": [],
      "source": [
        "lista_trafos = df_filtrado['TRAFO'].unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1qWZq2lvG-c"
      },
      "outputs": [],
      "source": [
        "# # Lista de transformadores para análise\n",
        "# trafos_escolhidos = [\n",
        "#     # LESTE\n",
        "#     'BSA_DJ_12B1', 'CAA_DJ_12B1', 'MAA_DJ_12B1',\n",
        "\n",
        "#     # CENTRO\n",
        "#     'ARA_DJ_12B1', 'BQR_DJ_12B1', 'RIC_DJ_12B1',\n",
        "\n",
        "#     # OESTE\n",
        "#     'CRM_DJ_12T1', 'PBL_DJ_12B1', 'PTS_DJ_12B1'\n",
        "# ]\n",
        "\n",
        "trafos_escolhidos  = lista_trafos\n",
        "\n",
        "\n",
        "# Criando gráfico da Potência Aparente ao longo do tempo, separada por TRAFO\n",
        "# fig_aparente = px.line(df_filtrado, x='datahora', y='S', color='TRAFO',\n",
        "#                        title='Potência Aparente ao Longo do Tempo por Transformador',\n",
        "#                        labels={'S': 'Potência Aparente (kVA)', 'Dia': 'Data'})\n",
        "\n",
        "# Exibir ou salvar o gráfico em\n",
        "# fig_aparente.show()\n",
        "# fig_aparente.write_html(\"Demanda ao longo do tempo - IQR.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bif9f6uJVxZg"
      },
      "source": [
        "#### S + Potência Acumulada GD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2yB3d1Wpk_9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "# Fixando seeds para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "def plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(df_previsoes, y_test_inverso, label='Valores Reais', color='blue')\n",
        "    plt.plot(df_previsoes, y_pred, label=f'Predictions {modelo} - Transformer {trafo}', linestyle='--', color='orange')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Apparent Power')\n",
        "    plt.title(f'Predicted x Real Comparison - Transformer {trafo} ({modelo})')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    resultados = []\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        df = df_filtrado[df_filtrado['TRAFO'] == trafo]\n",
        "        df = df[['datahora', 'S', 'PotenciaAcumulada']]\n",
        "        df = df.set_index(['datahora']).resample('D').max()\n",
        "        df.sort_index(inplace=True)\n",
        "        df = df.interpolate(method='linear')\n",
        "\n",
        "        dados = df[['S', 'PotenciaAcumulada']].values\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        dados_normalizados = scaler.fit_transform(dados)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(janela, len(dados_normalizados)):\n",
        "            X.append(dados_normalizados[i-janela:i, :])\n",
        "            y.append(dados_normalizados[i, 0])  # Prevendo apenas \"S\"\n",
        "\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2])) if modelo == 'LSTM' else X.reshape(X.shape[0], -1)\n",
        "\n",
        "        split = int(len(X) * 0.83)\n",
        "        X_train, X_test = X[:split], X[split:]\n",
        "        y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "        if modelo == 'SVR':\n",
        "            regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "\n",
        "        elif modelo == 'RFR':\n",
        "            regressor = RandomForestRegressor(n_estimators=100, max_depth=20, max_features='sqrt', n_jobs=-1, random_state=42)\n",
        "\n",
        "        elif modelo == 'LSTM':\n",
        "            regressor = Sequential()\n",
        "            regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "            regressor.add(LSTM(units=50))\n",
        "            regressor.add(Dense(1))\n",
        "            regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
        "            regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        regressor.fit(X_train, y_train) if modelo != 'LSTM' else None\n",
        "        y_pred_normalizado = regressor.predict(X_test)\n",
        "        y_pred = scaler.inverse_transform(np.column_stack((y_pred_normalizado, np.zeros_like(y_pred_normalizado))))[:, 0]\n",
        "        y_test_inverso = scaler.inverse_transform(np.column_stack((y_test, np.zeros_like(y_test))))[:, 0]\n",
        "\n",
        "        mse = mean_squared_error(y_test_inverso, y_pred)\n",
        "        rmse = sqrt(mse)\n",
        "        mae = mean_absolute_error(y_test_inverso, y_pred)\n",
        "        r2 = r2_score(y_test_inverso, y_pred)\n",
        "\n",
        "        df_previsoes = df.index[split + janela:]\n",
        "        plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# Chamando para SVR, RFR e LSTM\n",
        "resultados_svr_S_GD = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='SVR', janela=365)\n",
        "# resultados_rfr = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='RFR', janela=365)\n",
        "# resultados_lstm = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='LSTM', janela=365, epochs=20, batch_size=32)\n",
        "\n",
        "print(\"Resultados SVR:\")\n",
        "print(resultados_svr_S_GD)\n",
        "# print(\"\\nResultados RFR:\")\n",
        "# print(resultados_rfr)\n",
        "# print(\"\\nResultados LSTM:\")\n",
        "# print(resultados_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7d_o5dbfeMl"
      },
      "source": [
        "#### S + Clientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzT-y1k6feMl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "# Fixando seeds para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "def plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(df_previsoes, y_test_inverso, label='Valores Reais', color='blue')\n",
        "    plt.plot(df_previsoes, y_pred, label=f'Predictions {modelo} - Transformer {trafo}', linestyle='--', color='orange')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Apparent Power')\n",
        "    plt.title(f'Predicted x Real Comparison - Transformer {trafo} ({modelo})')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    resultados = []\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        df = df_filtrado[df_filtrado['TRAFO'] == trafo]\n",
        "        df = df[['datahora', 'S',  'fornec_ALTA', 'fornec_BAIXA']]\n",
        "        df = df.set_index(['datahora']).resample('D').max()\n",
        "        df.sort_index(inplace=True)\n",
        "        df = df.interpolate(method='linear')\n",
        "\n",
        "        dados = df[['S', 'fornec_ALTA', 'fornec_BAIXA']].values\n",
        "        scaler_features = MinMaxScaler(feature_range=(0, 1))\n",
        "        dados_normalizados = scaler_features.fit_transform(dados)\n",
        "\n",
        "        scaler_S = MinMaxScaler(feature_range=(0, 1))\n",
        "        S_normalizado = scaler_S.fit_transform(df[['S']].values)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(janela, len(dados_normalizados)):\n",
        "            X.append(dados_normalizados[i-janela:i, :])\n",
        "            y.append(dados_normalizados[i, 0])  # Prevendo apenas \"S\"\n",
        "\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2])) if modelo == 'LSTM' else X.reshape(X.shape[0], -1)\n",
        "\n",
        "        split = int(len(X) * 0.83)\n",
        "        X_train, X_test = X[:split], X[split:]\n",
        "        y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "        if modelo == 'SVR':\n",
        "            regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "\n",
        "        elif modelo == 'RFR':\n",
        "            regressor = RandomForestRegressor(n_estimators=100, max_depth=20, max_features='sqrt', n_jobs=-1, random_state=42)\n",
        "\n",
        "        elif modelo == 'LSTM':\n",
        "            regressor = Sequential()\n",
        "            regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "            regressor.add(LSTM(units=50))\n",
        "            regressor.add(Dense(1))\n",
        "            regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
        "            regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        regressor.fit(X_train, y_train) if modelo != 'LSTM' else None\n",
        "\n",
        "        y_pred_normalizado = regressor.predict(X_test)  # forma (n_amostras, 1)\n",
        "        y_pred = scaler_S.inverse_transform(y_pred_normalizado.reshape(-1, 1))\n",
        "        y_test_inverso = scaler_S.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "\n",
        "        mse = mean_squared_error(y_test_inverso, y_pred)\n",
        "        rmse = sqrt(mse)\n",
        "        mae = mean_absolute_error(y_test_inverso, y_pred)\n",
        "        r2 = r2_score(y_test_inverso, y_pred)\n",
        "\n",
        "        df_previsoes = df.index[split + janela:]\n",
        "        plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# Chamando para SVR, RFR e LSTM\n",
        "resultados_svr_S_Clientes = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='SVR', janela=365)\n",
        "# resultados_rfr = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='RFR', janela=365)\n",
        "# resultados_lstm = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='LSTM', janela=365, epochs=20, batch_size=32)\n",
        "\n",
        "print(\"Resultados SVR:\")\n",
        "print(resultados_svr_S_Clientes)\n",
        "# print(\"\\nResultados RFR:\")\n",
        "# print(resultados_rfr)\n",
        "# print(\"\\nResultados LSTM:\")\n",
        "# print(resultados_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T46p29m2feMm"
      },
      "source": [
        "#### S + Clientes + Potência Acumulada GD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S4iGVD3feMm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "# Fixando seeds para reprodutibilidade\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "def plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo):\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(df_previsoes, y_test_inverso, label='Valores Reais', color='blue')\n",
        "    plt.plot(df_previsoes, y_pred, label=f'Predictions {modelo} - Transformer {trafo}', linestyle='--', color='orange')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Apparent Power')\n",
        "    plt.title(f'Predicted x Real Comparison - Transformer {trafo} ({modelo})')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    resultados = []\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        df = df_filtrado[df_filtrado['TRAFO'] == trafo]\n",
        "        df = df[['datahora', 'S', 'PotenciaAcumulada', 'fornec_ALTA', 'fornec_BAIXA']]\n",
        "        df = df.set_index(['datahora']).resample('D').max()\n",
        "        df.sort_index(inplace=True)\n",
        "        df = df.interpolate(method='linear')\n",
        "\n",
        "        dados = df[['S', 'PotenciaAcumulada', 'fornec_ALTA', 'fornec_BAIXA']].values\n",
        "        scaler_features = MinMaxScaler(feature_range=(0, 1))\n",
        "        dados_normalizados = scaler_features.fit_transform(dados)\n",
        "\n",
        "        scaler_S = MinMaxScaler(feature_range=(0, 1))\n",
        "        S_normalizado = scaler_S.fit_transform(df[['S']].values)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(janela, len(dados_normalizados)):\n",
        "            X.append(dados_normalizados[i-janela:i, :])\n",
        "            y.append(dados_normalizados[i, 0])  # Prevendo apenas \"S\"\n",
        "\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2])) if modelo == 'LSTM' else X.reshape(X.shape[0], -1)\n",
        "\n",
        "        split = int(len(X) * 0.83)\n",
        "        X_train, X_test = X[:split], X[split:]\n",
        "        y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "        if modelo == 'SVR':\n",
        "            regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "\n",
        "        elif modelo == 'RFR':\n",
        "            regressor = RandomForestRegressor(n_estimators=100, max_depth=20, max_features='sqrt', n_jobs=-1, random_state=42)\n",
        "\n",
        "        elif modelo == 'LSTM':\n",
        "            regressor = Sequential()\n",
        "            regressor.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "            regressor.add(LSTM(units=50))\n",
        "            regressor.add(Dense(1))\n",
        "            regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
        "            regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        regressor.fit(X_train, y_train) if modelo != 'LSTM' else None\n",
        "\n",
        "        y_pred_normalizado = regressor.predict(X_test)  # forma (n_amostras, 1)\n",
        "        y_pred = scaler_S.inverse_transform(y_pred_normalizado.reshape(-1, 1))\n",
        "        y_test_inverso = scaler_S.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "\n",
        "        mse = mean_squared_error(y_test_inverso, y_pred)\n",
        "        rmse = sqrt(mse)\n",
        "        mae = mean_absolute_error(y_test_inverso, y_pred)\n",
        "        r2 = r2_score(y_test_inverso, y_pred)\n",
        "\n",
        "        df_previsoes = df.index[split + janela:]\n",
        "        plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo)\n",
        "\n",
        "        resultados.append({\n",
        "            'Trafo': trafo,\n",
        "            'Modelo': modelo,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# Chamando para SVR, RFR e LSTM\n",
        "resultados_svr_S_Clientes_GD = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='SVR', janela=365)\n",
        "# resultados_rfr = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='RFR', janela=365)\n",
        "# resultados_lstm = treinar_e_prever_modelo(df_filtrado, trafos_escolhidos, modelo='LSTM', janela=365, epochs=20, batch_size=32)\n",
        "\n",
        "print(\"Resultados SVR:\")\n",
        "print(resultados_svr_S_Clientes_GD)\n",
        "# print(\"\\nResultados RFR:\")\n",
        "# print(resultados_rfr)\n",
        "# print(\"\\nResultados LSTM:\")\n",
        "# print(resultados_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzoDrLiGfeMn"
      },
      "outputs": [],
      "source": [
        "print(\"Resultados SVR - S + GD:\")\n",
        "print(resultados_svr_S_GD)\n",
        "\n",
        "print(\"Resultados SVR - S + Clientes:\")\n",
        "print(resultados_svr_S_Clientes)\n",
        "\n",
        "print(\"Resultados SVR - S + Clientes + GD:\")\n",
        "print(resultados_svr_S_Clientes_GD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imCpUZqyqhI_"
      },
      "source": [
        "#### Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvg-O5T1uMZi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "# Fixando seeds para reprodutibilidade\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "def plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo, fold):\n",
        "    plt.rcParams.update({'font.size': 16})\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(df_previsoes, y_test_inverso, label='Real values', color='blue')\n",
        "    plt.plot(df_previsoes, y_pred, label=f'Predicted values', linestyle='--', color='orange')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Apparent Power')\n",
        "    plt.title(f'Predicted vs Real Comparison - Transformer {trafo} ({modelo})')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    if fold == 5:\n",
        "        plt.savefig(f\"Plot_{trafo}_{modelo}.eps\", format=\"eps\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def walk_forward_validation(df_filtrado, trafos_escolhidos, modelo, janela, epochs=20, batch_size=32):\n",
        "    resultados = []\n",
        "\n",
        "    for trafo in trafos_escolhidos:\n",
        "        df = df_filtrado[df_filtrado['TRAFO'] == trafo]\n",
        "        df = df[['datahora', 'S']]\n",
        "        df = df.set_index(['datahora']).resample('D').max()\n",
        "        df.sort_index(inplace=True)\n",
        "        df['S'] = df['S'].interpolate(method='linear')\n",
        "\n",
        "        dados = df[['S']].values\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        dados_normalizados = scaler.fit_transform(dados)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(janela, len(dados_normalizados)):\n",
        "            X.append(dados_normalizados[i-janela:i, 0])\n",
        "            y.append(dados_normalizados[i, 0])\n",
        "\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        X = np.reshape(X, (X.shape[0], X.shape[1], 1)) if modelo == 'LSTM' else X\n",
        "\n",
        "        n_splits = 5  # Número de folds para validação walk-forward\n",
        "        split_size = len(X) // (n_splits + 1)\n",
        "\n",
        "        for fold in range(n_splits):\n",
        "            train_size = split_size * (fold + 1)\n",
        "            X_train, X_test = X[:train_size], X[train_size:train_size + split_size]\n",
        "            y_train, y_test = y[:train_size], y[train_size:train_size + split_size]\n",
        "\n",
        "            if modelo == 'SVR':\n",
        "                regressor = SVR(kernel='rbf', C=100, gamma=0.001, epsilon=0.01)\n",
        "            elif modelo == 'RFR':\n",
        "                regressor = RandomForestRegressor(n_estimators=100, max_features='sqrt', n_jobs=-1, random_state=42)\n",
        "            elif modelo == 'LSTM':\n",
        "                regressor = Sequential()\n",
        "                regressor.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "                regressor.add(Dropout(0.2))  # 20% dos neurônios desligados aleatoriamente para evitar overfitting\n",
        "                regressor.add(LSTM(units=50))\n",
        "                regressor.add(Dropout(0.2))\n",
        "                regressor.add(Dense(1))\n",
        "                regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
        "                regressor.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "            regressor.fit(X_train, y_train) if modelo != 'LSTM' else None\n",
        "            y_pred_normalizado = regressor.predict(X_test)\n",
        "            y_pred = scaler.inverse_transform(y_pred_normalizado.reshape(-1, 1))\n",
        "            y_test_inverso = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "            mse = mean_squared_error(y_test_inverso, y_pred)\n",
        "            rmse = sqrt(mse)\n",
        "            mae = mean_absolute_error(y_test_inverso, y_pred)\n",
        "            r2 = r2_score(y_test_inverso, y_pred)\n",
        "\n",
        "            df_previsoes = df.index[train_size + janela:train_size + janela + split_size]\n",
        "            plotar_resultados(df_previsoes, y_test_inverso, y_pred, trafo, modelo, fold + 1)\n",
        "\n",
        "            resultados.append({\n",
        "                'Trafo': trafo,\n",
        "                'Modelo': modelo,\n",
        "                'Fold': fold + 1,\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'R2': r2\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "# Chamando para SVR, RFR e LSTM\n",
        "resultados_svr = walk_forward_validation(df_filtrado, trafos_escolhidos, modelo='SVR', janela=365)\n",
        "resultados_rfr = walk_forward_validation(df_filtrado, trafos_escolhidos, modelo='RFR', janela=365)\n",
        "# resultados_lstm = walk_forward_validation(df_filtrado, trafos_escolhidos, modelo='LSTM', janela=365, epochs=20, batch_size=32)\n",
        "\n",
        "print(\"Resultados SVR:\")\n",
        "print(resultados_svr)\n",
        "print(\"\\nResultados RFR:\")\n",
        "print(resultados_rfr)\n",
        "# print(\"\\nResultados LSTM:\")\n",
        "# print(resultados_lstm)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}